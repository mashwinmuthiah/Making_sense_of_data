data.for.plot <- aggregate(housing.df$MEDV, by = list(housing.df$CHAS), FUN = mean)
names(data.for.plot) <- c("CHAS", "MeanMEDV")
barplot(data.for.plot$MeanMEDV, names.arg = data.for.plot$CHAS,
xlab = "CHAS", ylab = "Avg. MEDV")
# alternative plot with ggplot
ggplot(data.for.plot) + geom_bar(aes(x = CHAS, y = MeanMEDV), stat = "identity")
## barchart of CHAS vs. % CAT.MEDV
data.for.plot <- aggregate(housing.df$CAT..MEDV, by = list(housing.df$CHAS), FUN = mean)
names(data.for.plot) <- c("CHAS", "MeanCATMEDV")
barplot(data.for.plot$MeanCATMEDV * 100, names.arg = data.for.plot$CHAS,
xlab = "CHAS", ylab = "% of CAT.MEDV")
dfw<-read.csv("C:\Users\ashwi\Desktop\Ashwin\PS_DS\psds_data\airline_delay_causes")
dfw<-read.csv("C:\\Users\\ashwi\\Desktop\\Ashwin\\PS_DS\\psds_data\\airline_delay_causes")
dfw<-read.csv("C:\\Users\\ashwi\\Desktop\\Ashwin\\PS_DS\\psds_data\\airline_delay_causes")
dfw<-read.csv("C:\\Users\\ashwi\\Desktop\\Ashwin\\PS_DS\\psds_data\\airline_delay_causes.csv")
barplot(as.matrix(dfw)/6,cex.axis=0.5)
barplot(as.matrix(dfw)/6, cex.axis=.5)
sp500_px <- read.csv('C:\\Users\\ashwi\\Desktop\\Ashwin\\PS_DS\\psds_data\\sp500_px.csv')
sp500_sym <- read.csv('C:\\Users\\ashwi\\Desktop\\Ashwin\\PS_DS\\psds_data\\sp500_sym.csv', stringsAsFactors = FALSE)
read.csv("C:\\Users\\ashwi\\Desktop\\Ashwin\\PS_DS\\psds_data\\k_tax.csv")
read.csv("C:\\Users\\ashwi\\Desktop\\Ashwin\\PS_DS\\psds_data\\kc_tax.csv")
kc_tax<-read.csv("C:\\Users\\ashwi\\Desktop\\Ashwin\\PS_DS\\psds_data\\kc_tax.csv")
kc_tax0<-subset(kc_tax,TaxAssessedValue < 750000 & SqFtTotLiving>100 & SqFtTotLiving<3500)
length(kc_tax0)
kc_tax0
nrow(kc_tax0)
ncol(kc_tax0)
ncol(kc_tax0)
a<-kc_tax(TaxAssessedValue < 750000 & SqFtTotLiving>100 & SqFtTotLiving<3500)
a<-kc_tax(kc_tax$TaxAssessedValue < 750000 & kc_tax$SqFtTotLiving>100 & kc_tax$SqFtTotLiving<3500)
a<-kc_tax(kc_tax$TaxAssessedValue < "750000" & kc_tax$SqFtTotLiving>"100" & kc_tax$SqFtTotLiving<"3500")
a<-kc_tax[kc_tax$TaxAssessedValue < "750000" & kc_tax$SqFtTotLiving>"100" & kc_tax$SqFtTotLiving<"3500"]
a<-Kc_tax[kc_tax$TaxAssessedValue < "750000" & kc_tax$SqFtTotLiving>"100" & kc_tax$SqFtTotLiving<"3500"]
a<-kc_tax[kc_tax$TaxAssessedValue < "750000" & kc_tax$SqFtTotLiving>"100" & kc_tax$SqFtTotLiving<"3500"]
a<- kc_tax [kc_tax$TaxAssessedValue < "750000" & kc_tax$SqFtTotLiving>"100" & kc_tax$SqFtTotLiving<"3500"]
ncol(kc_tax0)
library(ggplot2)
ggplot(kc_tax0, (aes(x=SqFtTotLiving, y=TaxAssessedValue))) + stat_binhex(colour="white") + theme_bw() + scale_fill_gradient(low="white", high="black") + labs(x="Finished Square Feet", y="Tax Assessed Value")
install.packages("hexbin")
ggplot(kc_tax0, (aes(x=SqFtTotLiving, y=TaxAssessedValue))) + stat_binhex(colour="white") + theme_bw() + scale_fill_gradient(low="white", high="black") + labs(x="Finished Square Feet", y="Tax Assessed Value")
ggplot(kc_tax0, (aes(x=SqFtTotLiving, y=TaxAssessedValue)))
ggplot(kc_tax0, (aes(x=SqFtTotLiving, y=TaxAssessedValue))) +  stat_binhex(colour="white") + theme_bw() + scale_fill_gradient(low="white", high="black") + labs(x="Finished Square Feet", y="Tax Assessed Value")
ggplot(kc_tax0, (aes(x=SqFtTotLiving, y=TaxAssessedValue))) +  stat_binhex(colour="white")
ggplot(kc_tax0, (aes(x=SqFtTotLiving, y=TaxAssessedValue)))
stat_binhex(colour="white")
ggplot(kc_tax0, (aes(x=SqFtTotLiving, y=TaxAssessedValue))) +  stat_binhex(colour="white")
ggplot(kc_tax0, (aes(x=SqFtTotLiving, y=TaxAssessedValue))) +  stat_binhex(colour="white") + theme_bw()
ggplot(kc_tax0, (aes(x=SqFtTotLiving, y=TaxAssessedValue))) +  stat_binhex(colour="white")
ggplot(kc_tax0, (aes(x=SqFtTotLiving, y=TaxAssessedValue))) +  stat_binhex(colour="white")  + scale_fill_gradient(low="white", high="black")
ggplot(kc_tax0, (aes(x=SqFtTotLiving, y=TaxAssessedValue))) +  stat_binhex(colour="white")  +theme_bw()+ scale_fill_gradient(low="white", high="black")
ggplot(kc_tax0, (aes(x=SqFtTotLiving, y=TaxAssessedValue))) +  stat_binhex(colour="white")  +theme_bw()+ scale_fill_gradient(low="white", high="red")
x <- rnorm(20000)
y <- rnorm(20000)
hbin <- hexbin(x,y, xbins = 40)
plot(hbin)
x <- kc_tax0$SqFtTotLiving
y <- kc_tax0$TaxAssessedValue
hbin <- hexbin(x,y, xbins = 40)
plot(hbin)
ggplot(kc_tax0, aes(SqFtTotLiving, TaxAssessedValue)) +
theme_bw() +
geom_point( alpha=0.1) +
geom_density2d(colour="white") +
labs(x="Finished Square Feet", y="Tax Assessed Value")
ggplot(kc_tax0, aes(SqFtTotLiving, TaxAssessedValue)) + theme_bw() + geom_point( alpha=0.1) + geom_density2d(colour="white") + labs(x="Finished Square Feet", y="Tax Assessed Value")
ggplot(kc_tax0, aes(SqFtTotLiving, TaxAssessedValue)) + theme_bw() + geom_point( alpha=0.1) + geom_density2d(colour="white") + labs(x="Finished Square Feet", y="Tax Assessed Value")
ctor<- contour(x,y)
ctor<- contour(x,y,alpha=0.1)
ggplot(kc_tax0, aes(SqFtTotLiving, TaxAssessedValue)) +
theme_bw() +
geom_point( alpha=0.1) +
geom_density2d(colour="white") +
labs(x="Finished Square Feet", y="Tax Assessed Value")
boxplot(pct_delay ~ airline, data=airline_stats, ylim=c(0, 50))
boxplot(pct_delay ~ airline, data=airline_stats, ylim=c(0, 50))
airline<-read.csv("C:\\Users\\ashwi\\Desktop\\Ashwin\\PS_DS\\psds_data\\airline_stats.csv")
boxplot(pct_delay ~ airline, data=airline_stats, ylim=c(0, 50))
boxplot(pct_delay = airline, data=airline_stats, ylim=c(0, 50))
boxplot(data=airline_stats, ylim=c(0, 50))
boxplot(data=airline_stats.csv, ylim=c(0, 50))
ggplot(kc_tax0,zipcode %in% c((98188, 98105, 98108, 98126)),aes(x=SqFtTotLiving, y=TaxAssessedValue))+stat_bin_hex(color ='white') +theme_bw()+scale_fill_gradient(low = "white",high = "red")
ggplot(kc_tax0,zipcode %in% c((98188,98105,98108,98126)),aes(x=SqFtTotLiving, y=TaxAssessedValue))+stat_bin_hex(color ='white') +theme_bw()+scale_fill_gradient(low = "white",high = "red")
ggplot(subset(kc_tax0, ZipCode %in% c(98188, 98105, 98108, 98126)),
aes(x=SqFtTotLiving, y=TaxAssessedValue)) +
stat_binhex(colour="white") +
theme_bw() +
scale_fill_gradient( low="white", high="blue") +
labs(x="Finished Square Feet", y="Tax Assessed Value") +
facet_wrap("ZipCode")
ggplot2(subset(kc_tax0, ZipCode %in% c(98188, 98105, 98108, 98126)),aes(x=SqFtTotLiving, y=TaxAssessedValue)) +stat_binhex(colour="white") +theme_bw() +scale_fill_gradient( low="white", high="blue") +facet_wrap("ZipCode")
library(ggplot)
library(ggplot2)
ggplot(subset(kc_tax0, ZipCode %in% c(98188, 98105, 98108, 98126)),aes(x=SqFtTotLiving, y=TaxAssessedValue)) +stat_binhex(colour="white") +theme_bw() +scale_fill_gradient( low="white", high="blue") +facet_wrap("ZipCode")
ggplot(kc_tax0,zipcode %in% c((98188,98105,98108,98126)),aes(x=SqFtTotLiving, y=TaxAssessedValue))+stat_bin_hex(color ='white') +theme_bw()+scale_fill_gradient(low = "white",high = "red")
ggplot(subset(kc_tax0,zipcode %in% c((98188,98105,98108,98126)),aes(x=SqFtTotLiving, y=TaxAssessedValue))+stat_bin_hex(color ='white') +theme_bw()+scale_fill_gradient(low = "white",high = "red")
library(ggplot2)
ggplot(subset(kc_tax0,zipcode %in% c((98188,98105,98108,98126)),aes(x=SqFtTotLiving, y=TaxAssessedValue))+stat_bin_hex(color ='white') +theme_bw()+scale_fill_gradient(low = "white",high = "red")
ggplot(subset(kc_tax0,zipcode %in% c((98188,98105,98108,98126)),aes(x=SqFtTotLiving, y=TaxAssessedValue))+stat_bin_hex(color ='white') +theme_bw()+scale_fill_gradient(low = "white",high = "red")
ggplot(subset(kc_tax0,ZipCode %in% c(98188, 98105, 98108, 98126)),aes(x=SqFtTotLiving, y=TaxAssessedValue)) +stat_binhex(colour="white") +theme_bw() +scale_fill_gradient( low="white", high="blue") +facet_wrap("ZipCode")
ggplot(subset(kc_tax0,zipcode %in% c(98188,98105,98108,98126)),aes(x=SqFtTotLiving, y=TaxAssessedValue))+stat_bin_hex(color ='white') +theme_bw()+scale_fill_gradient(low = "white",high = "red")
ggplot(subset(kc_tax0,zipcode %in% c(98188,98105,98108,98126)),aes(x=SqFtTotLiving, y=TaxAssessedValue))+stat_bin_hex(color ='white') +theme_bw()+scale_fill_gradient(low = "white",high = "red") + facet_wrap("ZipCode")
98188, 98105, 98108, 98126)),aes(x=SqFtTotLiving, y=TaxAssessedValue)) +stat_binhex(colour="white") +theme_bw() +scale_fill_gradient( low="white", high="blue") +facet_wrap("ZipCode")
library(ggplot2)
ggplot(subset(kc_tax0,ZipCode %in% c(98188, 98105, 98108, 98126)),aes(x=SqFtTotLiving, y=TaxAssessedValue)) +stat_binhex(colour="white") +theme_bw() +scale_fill_gradient( low="white", high="blue") +facet_wrap("ZipCode")
install.packages('IRkernel')
IRkernel::installspec()
IRkernel::installspec()
devtools::install_github('IRkernel/IRkernel')
IRkernel::installspec(user = FALSE)
install.packages(c('repr','IRdisplay','crayon','pbdZMQ','devtools'))
install.packages(c("repr", "IRdisplay", "crayon", "pbdZMQ", "devtools"))
install.packages(c("repr", "IRdisplay", "crayon", "pbdZMQ", "devtools"))
devtools::install_github('IRkernel/IRkernel')
IRkernel::installspec()
IRkernel::installspec()
install.packages('IRkernel')
install.packages("IRkernel")
IRkernel::installspec()
IRkernel::installspec(name = 'ir33', displayname = 'R 3.3')
IRkernel::installspec(name = 'ir32', displayname = 'R 3.2')
IRkernel::installspec()
IRkernel::installspec(user=FALSE)
conda install -c r r-irkernel
library(readr)
Vertebral_Column_Data <- read_csv("C:/Users/ashwi/Desktop/Ashwin/Making_sense_of_data/IE7275 working/Vertebral Column Data.csv")
View(Vertebral_Column_Data)
v <- Vertebral_Column_Data
fa.parallel(v,fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
v <- Vertebral_Column_Data
library(psych)
fa.parallel(v,fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
fa.parallel(v[,],fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
fa.parallel(v[,-1],fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
v <- Vertebral_Column_Data
library(psych)
fa.parallel(v[,-1],fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
fa.parallel(v[1,4],fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
fa.parallel(v[1,5],fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
v <- Vertebral_Column_Data
View(v)
fa.parallel(v[,6],fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
fa.parallel(v[,-1],fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
fa.parallel(v[,-2],fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
fa.parallel(v[,-5],fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
fa.parallel(v[,-6],fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
fa.parallel(v[,-67,fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
fa.parallel(v[,-7,fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
fa.parallel(v[,-7],fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
v[,1]
v[,-1]
v[,-2]
v[,-7]
cmdscale(v)
cmdscale(v[,-7])
cmdscale(v)
cmdscale(v[,-])
cmdscale(v[,-7])
cmdscale(v[,-7], k = 2, eig = FALSE, add = FALSE, x.ret = FALSE,
list. = eig || add || x.ret)
cmdscale(v[,-7], k = 2, eig = FALSE, add = FALSE, x.ret = FALSE)
cmdscale(v[,-7])
pc<-principal(v[,-7],nfactors = 1)
cmdscale(pc)
pc
cmdscale(pc[,-1])
cmdscale(pc)
rc<-principal(r=v[,-7],nfactors = 2,rotate = "varimax")
rc
cmdscale(pc)
cmdscale(rc)
cmdscale(pc)
setwd("C:/Users/ashwi/Desktop/Ashwin/Making_sense_of_data/IE7275 working")
#view the .dat file
USJudgeRatings
#chanign the file name for east access
uj <- USJudgeRatings
View(uj)
#view the .dat file
USJudgeRatings
#chanign the file name for east access
uj <- USJudgeRatings
View(uj)
library(psych)
fa.parallel(uj[,-1],fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
pc<-principal(uj[,-1],nfactors = 1)
pc
rc<-principal(r=uj,nfactors = 2,rotate = "varimax")
rc
pc<-principal(uj[,-1],nfactors = 1,score=TRUE)
head(pc$scores)
factor.plot(pc)
fa.parallel(uj[,-1],fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
fa.parallel(uj[,-1],fa="pc",n.iter = 100,show.legend = FALSE,main = "Scree plot with parallel analysis")
pc<-principal(uj[,-1],nfactors = 1)
pc
rc<-principal(r=uj,nfactors = 2,rotate = "varimax")
rc
pc<-principal(uj[,-1],nfactors = 1,score=TRUE)
head(pc$scores)
factor.plot(pc)
gi<-Glass_Identification_Data
View(gi)
setwd("C:/Users/ashwi/Desktop/Ashwin/Making_sense_of_data/IE7275 working")
gi<-Glass_Identification_Data
library(readr)
Glass_Identification_Data <- read_csv("Glass Identification Data.csv")
View(Glass_Identification_Data)
gi<-Glass_Identification_Data
library(psych)
fa.parallel(gi[,-1],fa="pc",n.iter = 100,show.legend = FALSE,main = "scree plot")
fa.parallel(gi[,-1],fa="pc",n.iter = 100,show.legend = FALSE,main = "Scree plot with parallel analysis")
pc<-principal(gi[,-1],nfactors = 1)
pc
rc<-principal(r=gi,nfactors = 2,rotate = "varimax")
rc
pc<-principal(gi[,-1],nfactors = 1,score=TRUE)
head(pc$scores)
factor.plot(pc)
pc<-principal(gi[,-1],nfactors = 1)
pc
rc<-principal(r=gi,nfactors = 2,rotate = "varimax")
rc
pc<-principal(gi[,-1],nfactors = 1,score=TRUE)
head(pc$scores)
fa.parallel(gi[,-1],fa="pc",n.iter = 100,show.legend = FALSE,main = "Scree plot with parallel analysis")
fa.parallel(gi[1,11],fa="pc",n.iter = 100,show.legend = FALSE,main = "Scree plot with parallel analysis")
fa.parallel(gi(1,11),fa="pc",n.iter = 100,show.legend = FALSE,main = "Scree plot with parallel analysis")
fa.parallel(gi(1,11),fa="pc",n.iter = 100,show.legend = FALSE,main = "Scree plot with parallel analysis")
pc<-principal(gi[,-1],nfactors = 4)
pc
fa.parallel(,gi(1,11),fa="pc",n.iter = 100,show.legend = FALSE,main = "Scree plot with parallel analysis")
fa.parallel(gi[,gi(1,11)],fa="pc",n.iter = 100,show.legend = FALSE,main = "Scree plot with parallel analysis")
fa.parallel(gi[,c(1,11)],fa="pc",n.iter = 100,show.legend = FALSE,main = "Scree plot with parallel analysis")
# Deleting ID and Class column
filter.data <- gi[,c(-1,-11)]
n.factor <- fa.parallel(filter.data)$nfact
n.factor <- fa.parallel(filter.data,pc="pc")$nfact
n.factor <- fa.parallel(filter.data,fa="pc")$nfact
pc <- principal(filter.data, nfactors = n.factor, rotate = "none", scores = TRUE)
pc
rc <- principal(filter.data, nfactors = n.factor, rotate = "varimax", scores = TRUE)
rc
factor.plot(pc)
dataset <- read.csv ("Glass Identification Data.csv")
filter.data <- dataset[,c(-1,-11)]
n.factor <- fa.parallel(filter.data)$nfact
n.factor <- fa.parallel(filter.data,fa="pc")$nfact
dataset <- USJudgeRatings
filter.data <- dataset[,c(-1,-11)]
n.factor <- fa.parallel(USJudgeRatings,fa="pc")$nfact
# Extract components without rotation
pc <- principal(USJudgeRatings, nfactors = n.factor, rotate = "none", scores = TRUE)
pc
# Extract components with rotation
rc <- principal(USJudgeRatings, nfactors = n.factor, rotate = "varimax", scores = TRUE)
rc
# Compute scores
pc.score <- pc$scores
rc.score <- rc$scores
# Graph
factor.plot(pc, labels = rownames(pc$loadings))
# Extract components without rotation
pc <- principal(USJudgeRatings, nfactors = n.factor, rotate = "none", scores = TRUE)
pc
# Extract components with rotation
rc <- principal(USJudgeRatings, nfactors = n.factor, rotate = "varimax", scores = TRUE)
rc
# Compute scores
pc.score <- pc$scores
rc.score <- rc$scores
# Graph
factor.plot(pc, labels = rownames(pc$loadings))
# Graph
factor.plot(pc)
# Determine number of components to extract
n.factor <- fa.parallel(USJudgeRatings,fa="pc")$nfact
# Extract components without rotation
pc <- principal(USJudgeRatings, nfactors = n.factor, rotate = "none", scores = TRUE)
pc
# Extract components with rotation
rc <- principal(USJudgeRatings, nfactors = n.factor, rotate = "varimax", scores = TRUE)
rc
# Compute scores
pc.score <- pc$scores
rc.score <- rc$scores
# Extract components without rotation
pc <- principal(USJudgeRatings, nfactors = n.factor, rotate = "none", scores = TRUE)
pc
library(psych)
# Extract components without rotation
pc <- principal(USJudgeRatings, nfactors = n.factor, rotate = "none", scores = TRUE)
pc
# Determine number of components to extract
n.factor <- fa.parallel(USJudgeRatings,fa="pc")$nfact
# Determine number of components to extract
n.factor <- fa.parallel(USJudgeRatings,fa="pc")$nfact
library(psych)
# Extract components without rotation
pc <- principal(USJudgeRatings, nfactors = n.factor, rotate = "none", scores = TRUE)
pc
# Extract components without rotation
pc <- principal(USJudgeRatings, nfactors = n.factor, rotate = "none", scores = TRUE)
# Extract components without rotation
pc <- principal(USJudgeRatings, rotate = "none", scores = TRUE)
pc
# Extract components without rotation
pc <- principal(USJudgeRatings, nfactors = 4, rotate = "none", scores = TRUE)
pc
# Determine number of components to extract
n.factor <- fa.parallel(USJudgeRatings)$nfact
# Extract components without rotation
pc <- principal(USJudgeRatings, nfactors = n.factor, rotate = "none", scores = TRUE)
pc
#view the .dat file
USJudgeRatings
#chanign the file name for easy access
uj <- USJudgeRatings
View(uj)
library(psych)
fa.parallel(uj[,-1],fa="pc",n.iter = 100,show.legend = FALSE,main = "Scree plot with parallel analysis")
pc<-principal(uj[,-1],nfactors = 1)
pc
rc<-principal(r=uj,nfactors = 2,rotate = "varimax")
ffac <-fa.parallel(uj[,-1],fa="pc",n.iter = 100,show.legend = FALSE,main = "Scree plot with parallel analysis")
ffac <-fa.parallel(uj[,-1],fa="pc",n.iter = 100,show.legend = FALSE,main = "Scree plot with parallel analysis")$nfact
ffac <-fa.parallel(uj[,-1],fa="pc",n.iter = 100,show.legend = FALSE,main = "Scree plot with parallel analysis")
fa.parallel(uj[,-1],fa="pc",n.iter = 100,show.legend = FALSE,main = "Scree plot with parallel analysis")
pc<-principal(uj[,-1],nfactors = 1)
pc
dataset <- read.csv ("Glass Identification Data.csv")
# Deleting ID and Class column
filter.data <- dataset[,c(-1,-11)]
n.factor <- fa.parallel(filter.data,fa="pc")$nfact
fa.parallel(filter.data,fa="pc")$nfact
fa.parallel(filter.data,fa="pc")
# Determine number of components to extract
n.factor <- fa.parallel(filter.data)$nfact
# Determine number of components to extract
n.factor <- fa.parallel(filter.data)$nfact
# Extract components without rotation
pc <- principal(filter.data, nfactors = n.factor, rotate = "none", scores = TRUE)
pc
# Extract components with rotation
rc <- principal(filter.data, nfactors = n.factor, rotate = "varimax", scores = TRUE)
rc
# Compute scores
pc.score <- pc$scores
rc.score <- rc$scores
factor.plot(pc, labels = rownames(pc$loadings))
factor.plot(rc, labels = rownames(pc$loadings))
#plots
factor.plot(pc)
factor.plot(rc)
# Deleting ID and Class column
filter.data <- dataset[,c(-1,-11)]
# Determine number of components to extract
n.factor <- fa.parallel(filter.data)$nfact
# Extract components without rotation
pc <- principal(filter.data, nfactors = n.factor, rotate = "none", scores = TRUE)
pc
# Extract components with rotation
rc <- principal(filter.data, nfactors = n.factor, rotate = "varimax", scores = TRUE)
rc
# Compute scores
pc.score <- pc$scores
rc.score <- rc$scores
pc.score
head(pc.score)
head(rc.score)
#plots
factor.plot(pc)
factor.plot(rc)
View(Harman23.cor)
h23<-Harman23.cor
library(psych)
covariances <- h23$cov
correlations<-cov2cor(covariances)
fa.parallel(correlations,fa="both",n.obs =112,main = "scree plot")
fa(r=correlations,nfactors = 2,rotate = "none",fm="pa")
fa.varimax<-fa(correlations,nfactors = 2,rotate = "varimax",fm="pa")
fa.varimax
fa.varimax$weights
factor.plot(fa.varimax)
factor.plot(fa.varimax,labels = rownames(fa$loadings))
factor.plot(fa.varimax,labels = rownames(fa.varimax$loadings))
fa.promax
fa.promax <-fa(correlations,nfactors = 2,rotate = "promax",fm="pa")
fa.promax
factor.plot(fa.promax)
fa.diagram(fa.promax,simple = FALSE)
fa.varimax<-fa(correlations,nfactors = 2,rotate = "varimax",fm="pa")
fa.varimax
fa.varimax$weights
factor.plot(fa.varimax,labels = rownames(fa.varimax$loadings))
fa.diagram(fa.varimax,simple = FALSE)
fa.diagram(fa,simple = FALSE)
fa.diagram(fa.varimax,simple = FALSE)
factor.plot(fa.varimax,labels = rownames(fa.varimax$loadings))
fa.diagram(fa.varimax,simple = FALSE)
View(Harman23.cor)
h23<-Harman23.cor
library(psych)
covariances <- h23$cov
correlations<-cov2cor(covariances)
fa.parallel(correlations,fa="both",n.obs =112,main = "scree plot")
fa(r=correlations,nfactors = 2,rotate = "none",fm="pa")
#orthogonal rotation
fa.varimax<-fa(correlations,nfactors = 2,rotate = "varimax",fm="pa")
fa.varimax
#oblique rotation
fa.promax <-fa(correlations,nfactors = 2,rotate = "promax",fm="pa")
fa.promax
#orthogonal rotation
fa.varimax<-fa(correlations,nfactors = 2,rotate = "varimax",fm="pa")
fa.varimax
fa.varimax$weights
factor.plot(fa.varimax,labels = rownames(fa.varimax$loadings))
fa.diagram(fa.varimax,simple = FALSE)
fa.diagram(fa.promax,simple = FALSE)
#orthogonal rotation
fa.varimax<-fa(correlations,nfactors = 2,rotate = "varimax",fm="pa")
fa.varimax
fa.varimax$weights
factor.plot(fa.varimax,labels = rownames(fa.varimax$loadings))
factor.plot(fa.varimax,labels = rownames(fa.varimax$loadings))
factor.plot(fa.promax)
#orthogonal rotation
fa.varimax<-fa(correlations,nfactors = 2,rotate = "varimax",fm="pa")
fa.varimax
fa.varimax$weights
factor.plot(fa.varimax,labels = rownames(fa.varimax$loadings))
#oblique rotation
fa.promax <-fa(correlations,nfactors = 2,rotate = "promax",fm="pa")
fa.promax
fa.promax$weights
factor.plot(fa.promax)
fa.diagram(fa.promax,simple = FALSE)
View(Harman74.cor)
h74<-Harman74.cor
library(psych)
covariances <- h74$cov
correlations<-cov2cor(covariances)
fa.parallel(correlations,fa="both",n.obs =112,main = "scree plot")
covariances <- h74$cov
correlations<-cov2cor(covariances)
fa.parallel(correlations,fa="both",n.obs =112,main = "scree plot")
fa(r=correlations,nfactors = 2,rotate = "none",fm="pa")
#orthogonal rotation
fa.varimax<-fa(correlations,nfactors = 2,rotate = "varimax",fm="pa")
fa.varimax
fa.varimax$weights
factor.plot(fa.varimax,labels = rownames(fa.varimax$loadings))
#orthogonal rotation
fa.varimax<-fa(correlations,nfactors = 4,rotate = "varimax",fm="pa")
fa.varimax
fa.varimax$weights
factor.plot(fa.varimax,labels = rownames(fa.varimax$loadings))
factor.plot(fa.varimax)
factor.plot(fa.varimax)
fa.diagram(fa.varimax,simple = FALSE)
#oblique rotation
fa.promax <-fa(correlations,nfactors = 2,rotate = "promax",fm="pa")
fa.promax
fa.promax$weights
# Import data
dataset <- read.csv("Vertebral Column Data.csv")
# Remove Class column
filter.data <- dataset[,-7]
# Checking Missing values
sum(is.na(filter.data))
# Determine number of components
n.comp <- fa.parallel(filter.data)$nfact
# Multidimensional Scaling
scaled.data <- cmdscale(dist(filter.data))
# Graph
pc <- principal(filter.data, nfactors = n.comp, scores = TRUE)
factor.plot(pc)
library(psych)
# Remove Class column
filter.data <- dataset[,-7]
# Import data
dataset <- read.csv("Vertebral Column Data.csv")
library(psych)
# Remove Class column
filter.data <- dataset[,-7]
# Checking Missing values
sum(is.na(filter.data))
# Determine number of components
n.comp <- fa.parallel(filter.data)$nfact
# Determine number of components
n.comp <- fa.parallel(filter.data)$nfact
# Multidimensional Scaling
scaled.data <- cmdscale(dist(filter.data))
# Graph
pc <- principal(filter.data, nfactors = n.comp, scores = TRUE)
factor.plot(pc)
# Import data
dataset <- read.csv("Vertebral Column Data.csv")
library(psych)
# Remove Class column
filter.data <- dataset[,-7]
# Checking Missing values
sum(is.na(filter.data))
# Determine number of components
n.comp <- fa.parallel(filter.data)$nfact
# Multidimensional Scaling
scaled.data <- cmdscale(dist(filter.data))
scaled.data
head(scaled.data)
# Graph
pc <- principal(filter.data, nfactors = n.comp, scores = TRUE)
factor.plot(pc)
